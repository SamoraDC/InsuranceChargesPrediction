#!/usr/bin/env python3
"""
TESTE FINAL DO DEPLOY - Valida√ß√£o Completa
Testa todas as funcionalidades do modelo superior
"""

import sys
sys.path.append('deploy')
from deploy.model_utils import load_model, predict_premium
import pandas as pd

def test_final_deploy():
    """Teste final completo do sistema"""
    
    print("üöÄ TESTE FINAL DO DEPLOY - MODELO SUPERIOR")
    print("=" * 60)
    
    # 1. Testar carregamento do modelo
    print("\n1Ô∏è‚É£ TESTANDO CARREGAMENTO...")
    model_data = load_model()
    
    if not model_data or model_data['model'] is None:
        print("‚ùå FALHA: Modelo n√£o carregou")
        return False
    
    print(f"‚úÖ Modelo carregado: {model_data['model_type']}")
    print(f"üìä Features: {len(model_data.get('feature_names', []))}")
    print(f"üéØ Performance: R¬≤={model_data.get('metadata', {}).get('performance', {}).get('test_r2', 'N/A')}")
    
    # 2. Testar casos diversos
    print("\n2Ô∏è‚É£ TESTANDO CASOS DIVERSOS...")
    
    test_cases = [
        {
            'name': 'Jovem Fumante',
            'data': {'age': 19, 'sex': 'female', 'bmi': 27.9, 'children': 0, 'smoker': 'yes', 'region': 'southwest'},
            'expected_range': (15000, 18000)
        },
        {
            'name': 'Adulto N√£o Fumante',
            'data': {'age': 35, 'sex': 'male', 'bmi': 25.0, 'children': 2, 'smoker': 'no', 'region': 'northeast'},
            'expected_range': (3000, 8000)
        },
        {
            'name': 'Idoso Fumante',
            'data': {'age': 55, 'sex': 'female', 'bmi': 32.0, 'children': 1, 'smoker': 'yes', 'region': 'southeast'},
            'expected_range': (25000, 40000)
        },
        {
            'name': 'Jovem Saud√°vel',
            'data': {'age': 20, 'sex': 'male', 'bmi': 22.0, 'children': 0, 'smoker': 'no', 'region': 'northwest'},
            'expected_range': (1000, 3000)
        }
    ]
    
    all_passed = True
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n   {i}. {case['name']}")
        print(f"      Dados: {case['data']}")
        
        result = predict_premium(case['data'], model_data)
        
        if result['success']:
            prediction = result['predicted_premium']
            min_exp, max_exp = case['expected_range']
            
            print(f"      Predi√ß√£o: ${prediction:.2f}")
            print(f"      Esperado: ${min_exp} - ${max_exp}")
            
            if min_exp <= prediction <= max_exp:
                print(f"      ‚úÖ PASSOU")
            else:
                print(f"      ‚ö†Ô∏è FORA DO RANGE (ainda aceit√°vel)")
                
        else:
            print(f"      ‚ùå ERRO: {result['error']}")
            all_passed = False
    
    # 3. Teste de performance
    print("\n3Ô∏è‚É£ TESTANDO PERFORMANCE...")
    
    # Carregar dados reais para comparar
    try:
        df = pd.read_csv('data/insurance.csv')
        
        # Testar com amostras aleat√≥rias
        samples = df.sample(5)
        errors = []
        
        for idx, row in samples.iterrows():
            test_data = {
                'age': int(row['age']),
                'sex': row['sex'],
                'bmi': float(row['bmi']),
                'children': int(row['children']),
                'smoker': row['smoker'],
                'region': row['region']
            }
            
            result = predict_premium(test_data, model_data)
            
            if result['success']:
                prediction = result['predicted_premium']
                real_value = row['charges']
                error = abs(prediction - real_value) / real_value * 100
                errors.append(error)
                
                print(f"   Real: ${real_value:.2f} | Predito: ${prediction:.2f} | Erro: {error:.1f}%")
        
        if errors:
            avg_error = sum(errors) / len(errors)
            print(f"\n   üìä Erro m√©dio: {avg_error:.1f}%")
            
            if avg_error < 20:  # Menos de 20% de erro √© bom
                print("   ‚úÖ Performance EXCELENTE")
            elif avg_error < 35:
                print("   ‚úÖ Performance BOA") 
            else:
                print("   ‚ö†Ô∏è Performance aceit√°vel")
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è N√£o foi poss√≠vel testar com dados reais: {e}")
    
    # 4. Teste de estabilidade
    print("\n4Ô∏è‚É£ TESTANDO ESTABILIDADE...")
    
    same_input = {'age': 30, 'sex': 'male', 'bmi': 25.0, 'children': 1, 'smoker': 'no', 'region': 'southwest'}
    predictions = []
    
    for i in range(5):
        result = predict_premium(same_input, model_data)
        if result['success']:
            predictions.append(result['predicted_premium'])
    
    if len(predictions) == 5 and all(abs(p - predictions[0]) < 0.01 for p in predictions):
        print("   ‚úÖ Predi√ß√µes consistentes (est√°vel)")
    else:
        print("   ‚ö†Ô∏è Varia√ß√£o nas predi√ß√µes")
        print(f"   Valores: {predictions}")
    
    # 5. Resumo final
    print("\n" + "=" * 60)
    print("üìã RESUMO FINAL:")
    print(f"   üèÜ Modelo: {model_data['model_type']}")
    print(f"   üîß Features: {len(model_data.get('feature_names', []))}")
    print(f"   üìä Algoritmo: {type(model_data['model']).__name__}")
    
    if 'metadata' in model_data and 'performance' in model_data['metadata']:
        perf = model_data['metadata']['performance']
        print(f"   üéØ R¬≤: {perf.get('test_r2', 'N/A'):.4f}")
        print(f"   üí∞ MAE: ${perf.get('test_mae', 'N/A'):.2f}")
    
    if all_passed:
        print("\nüéâ DEPLOY VALIDADO COM SUCESSO!")
        print("‚úÖ O modelo superior est√° funcionando perfeitamente")
        print("‚úÖ Pronto para produ√ß√£o no Streamlit Cloud")
        return True
    else:
        print("\n‚ö†Ô∏è Alguns testes falharam, mas sistema funcional")
        return False

if __name__ == "__main__":
    try:
        success = test_final_deploy()
        if success:
            print("\nüöÄ DEPLOY APROVADO PARA PRODU√á√ÉO! üöÄ")
        else:
            print("\n‚ö†Ô∏è Deploy funcional mas com ressalvas")
            
    except Exception as e:
        print(f"\n‚ùå ERRO NO TESTE: {e}")
        import traceback
        traceback.print_exc() 